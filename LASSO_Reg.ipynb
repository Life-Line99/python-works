{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.3"
    },
    "colab": {
      "name": "LASSO_Regression_Exercise2.ipynb",
      "provenance": [],
      "include_colab_link": true
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Life-Line99/python-works/blob/master/LASSO_Regression_Exercise2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "id": "j8Ty382VzbxR",
        "colab_type": "code",
        "colab": {},
        "outputId": "2c899f96-6f89-4921-a661-46a25f941b92"
      },
      "source": [
        "\n",
        "import pandas as pd\n",
        "import pandas\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LassoLarsCV\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# load data and preview\n",
        "alldata = pd.read_csv('finalmaster-ratios.csv')\n",
        "alldata.head()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th># Purchases</th>\n",
              "      <th>B01001001</th>\n",
              "      <th>B01001002</th>\n",
              "      <th>B01001003</th>\n",
              "      <th>B01001004</th>\n",
              "      <th>B01001005</th>\n",
              "      <th>B01001006</th>\n",
              "      <th>B01001007</th>\n",
              "      <th>B01001008</th>\n",
              "      <th>B01001009</th>\n",
              "      <th>...</th>\n",
              "      <th>B19001008</th>\n",
              "      <th>B19001009</th>\n",
              "      <th>B19001010</th>\n",
              "      <th>B19001011</th>\n",
              "      <th>B19001012</th>\n",
              "      <th>B19001013</th>\n",
              "      <th>B19001014</th>\n",
              "      <th>B19001015</th>\n",
              "      <th>B19001016</th>\n",
              "      <th>B19001017</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>22</td>\n",
              "      <td>206252</td>\n",
              "      <td>469.226965</td>\n",
              "      <td>31.432422</td>\n",
              "      <td>35.219052</td>\n",
              "      <td>33.628765</td>\n",
              "      <td>20.121017</td>\n",
              "      <td>12.610787</td>\n",
              "      <td>6.734480</td>\n",
              "      <td>6.225394</td>\n",
              "      <td>...</td>\n",
              "      <td>49.409690</td>\n",
              "      <td>53.306757</td>\n",
              "      <td>42.318307</td>\n",
              "      <td>83.167229</td>\n",
              "      <td>89.249208</td>\n",
              "      <td>102.141470</td>\n",
              "      <td>52.872330</td>\n",
              "      <td>36.440765</td>\n",
              "      <td>23.446284</td>\n",
              "      <td>21.197485</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>7</td>\n",
              "      <td>61399</td>\n",
              "      <td>486.538869</td>\n",
              "      <td>22.899396</td>\n",
              "      <td>21.531295</td>\n",
              "      <td>27.036271</td>\n",
              "      <td>16.808091</td>\n",
              "      <td>28.355511</td>\n",
              "      <td>18.192479</td>\n",
              "      <td>13.534422</td>\n",
              "      <td>...</td>\n",
              "      <td>59.231680</td>\n",
              "      <td>50.093078</td>\n",
              "      <td>40.700626</td>\n",
              "      <td>92.612963</td>\n",
              "      <td>117.363344</td>\n",
              "      <td>113.344051</td>\n",
              "      <td>75.774243</td>\n",
              "      <td>33.000508</td>\n",
              "      <td>33.169741</td>\n",
              "      <td>24.792689</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>3</td>\n",
              "      <td>73170</td>\n",
              "      <td>489.859232</td>\n",
              "      <td>28.905289</td>\n",
              "      <td>36.271696</td>\n",
              "      <td>28.235616</td>\n",
              "      <td>21.566216</td>\n",
              "      <td>12.218122</td>\n",
              "      <td>7.243406</td>\n",
              "      <td>7.380074</td>\n",
              "      <td>...</td>\n",
              "      <td>63.996993</td>\n",
              "      <td>47.322923</td>\n",
              "      <td>42.505211</td>\n",
              "      <td>70.420610</td>\n",
              "      <td>90.033143</td>\n",
              "      <td>98.677692</td>\n",
              "      <td>54.703249</td>\n",
              "      <td>20.125056</td>\n",
              "      <td>11.890525</td>\n",
              "      <td>16.537397</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>94</td>\n",
              "      <td>251724</td>\n",
              "      <td>505.585483</td>\n",
              "      <td>32.054949</td>\n",
              "      <td>31.757004</td>\n",
              "      <td>28.102207</td>\n",
              "      <td>18.651380</td>\n",
              "      <td>12.080692</td>\n",
              "      <td>7.035483</td>\n",
              "      <td>7.686991</td>\n",
              "      <td>...</td>\n",
              "      <td>54.790900</td>\n",
              "      <td>48.681562</td>\n",
              "      <td>43.873381</td>\n",
              "      <td>84.717507</td>\n",
              "      <td>112.204444</td>\n",
              "      <td>127.137252</td>\n",
              "      <td>83.019904</td>\n",
              "      <td>43.731067</td>\n",
              "      <td>38.851729</td>\n",
              "      <td>40.427349</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0</td>\n",
              "      <td>37382</td>\n",
              "      <td>495.586111</td>\n",
              "      <td>25.413301</td>\n",
              "      <td>29.318924</td>\n",
              "      <td>26.162324</td>\n",
              "      <td>19.260607</td>\n",
              "      <td>12.893906</td>\n",
              "      <td>6.580707</td>\n",
              "      <td>7.062222</td>\n",
              "      <td>...</td>\n",
              "      <td>58.883378</td>\n",
              "      <td>51.761414</td>\n",
              "      <td>47.310187</td>\n",
              "      <td>81.902582</td>\n",
              "      <td>93.793717</td>\n",
              "      <td>130.103014</td>\n",
              "      <td>71.982704</td>\n",
              "      <td>36.118530</td>\n",
              "      <td>31.603714</td>\n",
              "      <td>19.648989</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows Ã— 190 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "   # Purchases  B01001001   B01001002  B01001003  B01001004  B01001005  \\\n",
              "0           22     206252  469.226965  31.432422  35.219052  33.628765   \n",
              "1            7      61399  486.538869  22.899396  21.531295  27.036271   \n",
              "2            3      73170  489.859232  28.905289  36.271696  28.235616   \n",
              "3           94     251724  505.585483  32.054949  31.757004  28.102207   \n",
              "4            0      37382  495.586111  25.413301  29.318924  26.162324   \n",
              "\n",
              "   B01001006  B01001007  B01001008  B01001009  ...  B19001008  B19001009  \\\n",
              "0  20.121017  12.610787   6.734480   6.225394  ...  49.409690  53.306757   \n",
              "1  16.808091  28.355511  18.192479  13.534422  ...  59.231680  50.093078   \n",
              "2  21.566216  12.218122   7.243406   7.380074  ...  63.996993  47.322923   \n",
              "3  18.651380  12.080692   7.035483   7.686991  ...  54.790900  48.681562   \n",
              "4  19.260607  12.893906   6.580707   7.062222  ...  58.883378  51.761414   \n",
              "\n",
              "   B19001010  B19001011   B19001012   B19001013  B19001014  B19001015  \\\n",
              "0  42.318307  83.167229   89.249208  102.141470  52.872330  36.440765   \n",
              "1  40.700626  92.612963  117.363344  113.344051  75.774243  33.000508   \n",
              "2  42.505211  70.420610   90.033143   98.677692  54.703249  20.125056   \n",
              "3  43.873381  84.717507  112.204444  127.137252  83.019904  43.731067   \n",
              "4  47.310187  81.902582   93.793717  130.103014  71.982704  36.118530   \n",
              "\n",
              "   B19001016  B19001017  \n",
              "0  23.446284  21.197485  \n",
              "1  33.169741  24.792689  \n",
              "2  11.890525  16.537397  \n",
              "3  38.851729  40.427349  \n",
              "4  31.603714  19.648989  \n",
              "\n",
              "[5 rows x 190 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0Rsn_1FSzbxY",
        "colab_type": "code",
        "colab": {},
        "outputId": "a47e3343-cd65-4c90-a32d-4a8671170825"
      },
      "source": [
        "allvariablenames = list(alldata.columns.values)\n",
        "listofallpredictors = allvariablenames[8:]\n",
        "predictors = alldata[listofallpredictors]  \n",
        "\n",
        "#load target into dataframe\n",
        "target = alldata['# Purchases']   \n",
        "\n",
        "# split data into train and test sets, with 30% retained for test\n",
        "pred_train, pred_test, tar_train, tar_test = train_test_split(predictors, target, test_size=.3, random_state=123)    \n",
        "model = LassoLarsCV(precompute=False, cv=10)\n",
        "model.fit(pred_train, tar_train)\n",
        "\n",
        "\n",
        "     \n",
        "# Question 1: Comment in code."
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/Users/thepound/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/least_angle.py:578: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 5 iterations, i.e. alpha=1.496e+00, with an active set of 5 regressors, and the smallest cholesky pivot element being 6.495e-08. Reduce max_iter or increase eps parameters.\n",
            "  ConvergenceWarning)\n",
            "/Users/thepound/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/least_angle.py:578: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 8 iterations, i.e. alpha=1.098e+00, with an active set of 8 regressors, and the smallest cholesky pivot element being 6.495e-08. Reduce max_iter or increase eps parameters.\n",
            "  ConvergenceWarning)\n",
            "/Users/thepound/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/least_angle.py:578: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 10 iterations, i.e. alpha=7.329e-01, with an active set of 10 regressors, and the smallest cholesky pivot element being 6.495e-08. Reduce max_iter or increase eps parameters.\n",
            "  ConvergenceWarning)\n",
            "/Users/thepound/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/least_angle.py:578: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 13 iterations, i.e. alpha=6.051e-01, with an active set of 11 regressors, and the smallest cholesky pivot element being 6.495e-08. Reduce max_iter or increase eps parameters.\n",
            "  ConvergenceWarning)\n",
            "/Users/thepound/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/least_angle.py:604: ConvergenceWarning: Early stopping the lars path, as the residues are small and the current value of alpha is no longer well controlled. 17 iterations, alpha=5.739e-01, previous alpha=5.739e-01, with an active set of 14 regressors.\n",
            "  ConvergenceWarning)\n",
            "/Users/thepound/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/least_angle.py:578: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 16 iterations, i.e. alpha=4.100e-01, with an active set of 16 regressors, and the smallest cholesky pivot element being 2.107e-08. Reduce max_iter or increase eps parameters.\n",
            "  ConvergenceWarning)\n",
            "/Users/thepound/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/least_angle.py:578: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 27 iterations, i.e. alpha=2.867e-01, with an active set of 27 regressors, and the smallest cholesky pivot element being 5.674e-08. Reduce max_iter or increase eps parameters.\n",
            "  ConvergenceWarning)\n",
            "/Users/thepound/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/least_angle.py:578: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 44 iterations, i.e. alpha=2.050e-01, with an active set of 36 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
            "  ConvergenceWarning)\n",
            "/Users/thepound/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/least_angle.py:578: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 45 iterations, i.e. alpha=2.013e-01, with an active set of 37 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
            "  ConvergenceWarning)\n",
            "/Users/thepound/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/least_angle.py:604: ConvergenceWarning: Early stopping the lars path, as the residues are small and the current value of alpha is no longer well controlled. 46 iterations, alpha=1.986e-01, previous alpha=1.960e-01, with an active set of 37 regressors.\n",
            "  ConvergenceWarning)\n",
            "/Users/thepound/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/least_angle.py:578: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 4 iterations, i.e. alpha=1.365e+00, with an active set of 4 regressors, and the smallest cholesky pivot element being 6.234e-08. Reduce max_iter or increase eps parameters.\n",
            "  ConvergenceWarning)\n",
            "/Users/thepound/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/least_angle.py:578: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 7 iterations, i.e. alpha=1.008e+00, with an active set of 7 regressors, and the smallest cholesky pivot element being 6.234e-08. Reduce max_iter or increase eps parameters.\n",
            "  ConvergenceWarning)\n",
            "/Users/thepound/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/least_angle.py:578: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 9 iterations, i.e. alpha=8.144e-01, with an active set of 9 regressors, and the smallest cholesky pivot element being 6.234e-08. Reduce max_iter or increase eps parameters.\n",
            "  ConvergenceWarning)\n",
            "/Users/thepound/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/least_angle.py:578: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 10 iterations, i.e. alpha=6.642e-01, with an active set of 10 regressors, and the smallest cholesky pivot element being 6.234e-08. Reduce max_iter or increase eps parameters.\n",
            "  ConvergenceWarning)\n",
            "/Users/thepound/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/least_angle.py:578: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 13 iterations, i.e. alpha=5.644e-01, with an active set of 13 regressors, and the smallest cholesky pivot element being 2.107e-08. Reduce max_iter or increase eps parameters.\n",
            "  ConvergenceWarning)\n",
            "/Users/thepound/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/least_angle.py:578: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 13 iterations, i.e. alpha=5.644e-01, with an active set of 13 regressors, and the smallest cholesky pivot element being 2.581e-08. Reduce max_iter or increase eps parameters.\n",
            "  ConvergenceWarning)\n",
            "/Users/thepound/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/least_angle.py:604: ConvergenceWarning: Early stopping the lars path, as the residues are small and the current value of alpha is no longer well controlled. 16 iterations, alpha=5.626e-01, previous alpha=5.354e-01, with an active set of 13 regressors.\n",
            "  ConvergenceWarning)\n",
            "/Users/thepound/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/least_angle.py:578: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 4 iterations, i.e. alpha=1.439e+00, with an active set of 4 regressors, and the smallest cholesky pivot element being 3.650e-08. Reduce max_iter or increase eps parameters.\n",
            "  ConvergenceWarning)\n",
            "/Users/thepound/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/least_angle.py:578: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 9 iterations, i.e. alpha=1.037e+00, with an active set of 9 regressors, and the smallest cholesky pivot element being 3.650e-08. Reduce max_iter or increase eps parameters.\n",
            "  ConvergenceWarning)\n",
            "/Users/thepound/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/least_angle.py:604: ConvergenceWarning: Early stopping the lars path, as the residues are small and the current value of alpha is no longer well controlled. 15 iterations, alpha=7.201e-01, previous alpha=7.200e-01, with an active set of 12 regressors.\n",
            "  ConvergenceWarning)\n",
            "/Users/thepound/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/least_angle.py:578: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 7 iterations, i.e. alpha=1.132e+00, with an active set of 7 regressors, and the smallest cholesky pivot element being 8.625e-08. Reduce max_iter or increase eps parameters.\n",
            "  ConvergenceWarning)\n",
            "/Users/thepound/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/least_angle.py:578: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 8 iterations, i.e. alpha=8.548e-01, with an active set of 8 regressors, and the smallest cholesky pivot element being 4.081e-08. Reduce max_iter or increase eps parameters.\n",
            "  ConvergenceWarning)\n",
            "/Users/thepound/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/least_angle.py:578: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 15 iterations, i.e. alpha=5.662e-01, with an active set of 13 regressors, and the smallest cholesky pivot element being 8.560e-08. Reduce max_iter or increase eps parameters.\n",
            "  ConvergenceWarning)\n",
            "/Users/thepound/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/least_angle.py:578: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 16 iterations, i.e. alpha=5.278e-01, with an active set of 14 regressors, and the smallest cholesky pivot element being 9.996e-08. Reduce max_iter or increase eps parameters.\n",
            "  ConvergenceWarning)\n",
            "/Users/thepound/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/least_angle.py:578: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 16 iterations, i.e. alpha=5.245e-01, with an active set of 14 regressors, and the smallest cholesky pivot element being 2.581e-08. Reduce max_iter or increase eps parameters.\n",
            "  ConvergenceWarning)\n",
            "/Users/thepound/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/least_angle.py:604: ConvergenceWarning: Early stopping the lars path, as the residues are small and the current value of alpha is no longer well controlled. 18 iterations, alpha=5.567e-01, previous alpha=5.184e-01, with an active set of 15 regressors.\n",
            "  ConvergenceWarning)\n",
            "/Users/thepound/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/least_angle.py:578: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 4 iterations, i.e. alpha=1.572e+00, with an active set of 4 regressors, and the smallest cholesky pivot element being 3.650e-08. Reduce max_iter or increase eps parameters.\n",
            "  ConvergenceWarning)\n",
            "/Users/thepound/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/least_angle.py:578: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 10 iterations, i.e. alpha=1.132e+00, with an active set of 10 regressors, and the smallest cholesky pivot element being 3.650e-08. Reduce max_iter or increase eps parameters.\n",
            "  ConvergenceWarning)\n",
            "/Users/thepound/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/least_angle.py:578: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 12 iterations, i.e. alpha=7.640e-01, with an active set of 12 regressors, and the smallest cholesky pivot element being 3.650e-08. Reduce max_iter or increase eps parameters.\n",
            "  ConvergenceWarning)\n",
            "/Users/thepound/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/least_angle.py:578: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 26 iterations, i.e. alpha=3.863e-01, with an active set of 24 regressors, and the smallest cholesky pivot element being 2.581e-08. Reduce max_iter or increase eps parameters.\n",
            "  ConvergenceWarning)\n",
            "/Users/thepound/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/least_angle.py:578: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 26 iterations, i.e. alpha=3.863e-01, with an active set of 24 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.\n",
            "  ConvergenceWarning)\n",
            "/Users/thepound/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/least_angle.py:578: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 28 iterations, i.e. alpha=3.560e-01, with an active set of 24 regressors, and the smallest cholesky pivot element being 2.107e-08. Reduce max_iter or increase eps parameters.\n",
            "  ConvergenceWarning)\n",
            "/Users/thepound/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/least_angle.py:578: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 54 iterations, i.e. alpha=2.018e-01, with an active set of 36 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.\n",
            "  ConvergenceWarning)\n",
            "/Users/thepound/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/least_angle.py:578: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 55 iterations, i.e. alpha=1.901e-01, with an active set of 37 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.\n",
            "  ConvergenceWarning)\n",
            "/Users/thepound/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/least_angle.py:578: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 65 iterations, i.e. alpha=1.690e-01, with an active set of 47 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.\n",
            "  ConvergenceWarning)\n",
            "/Users/thepound/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/least_angle.py:604: ConvergenceWarning: Early stopping the lars path, as the residues are small and the current value of alpha is no longer well controlled. 67 iterations, alpha=1.728e-01, previous alpha=1.646e-01, with an active set of 48 regressors.\n",
            "  ConvergenceWarning)\n",
            "/Users/thepound/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/least_angle.py:578: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 4 iterations, i.e. alpha=1.644e+00, with an active set of 4 regressors, and the smallest cholesky pivot element being 3.332e-08. Reduce max_iter or increase eps parameters.\n",
            "  ConvergenceWarning)\n",
            "/Users/thepound/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/least_angle.py:578: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 7 iterations, i.e. alpha=1.178e+00, with an active set of 7 regressors, and the smallest cholesky pivot element being 3.332e-08. Reduce max_iter or increase eps parameters.\n",
            "  ConvergenceWarning)\n",
            "/Users/thepound/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/least_angle.py:578: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 9 iterations, i.e. alpha=9.316e-01, with an active set of 9 regressors, and the smallest cholesky pivot element being 3.332e-08. Reduce max_iter or increase eps parameters.\n",
            "  ConvergenceWarning)\n",
            "/Users/thepound/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/least_angle.py:578: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 10 iterations, i.e. alpha=8.155e-01, with an active set of 10 regressors, and the smallest cholesky pivot element being 3.332e-08. Reduce max_iter or increase eps parameters.\n",
            "  ConvergenceWarning)\n",
            "/Users/thepound/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/least_angle.py:604: ConvergenceWarning: Early stopping the lars path, as the residues are small and the current value of alpha is no longer well controlled. 32 iterations, alpha=3.203e-01, previous alpha=3.135e-01, with an active set of 25 regressors.\n",
            "  ConvergenceWarning)\n",
            "/Users/thepound/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/least_angle.py:578: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 4 iterations, i.e. alpha=1.368e+00, with an active set of 4 regressors, and the smallest cholesky pivot element being 6.322e-08. Reduce max_iter or increase eps parameters.\n",
            "  ConvergenceWarning)\n",
            "/Users/thepound/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/least_angle.py:578: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 7 iterations, i.e. alpha=1.031e+00, with an active set of 7 regressors, and the smallest cholesky pivot element being 6.322e-08. Reduce max_iter or increase eps parameters.\n",
            "  ConvergenceWarning)\n",
            "/Users/thepound/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/least_angle.py:578: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 9 iterations, i.e. alpha=7.535e-01, with an active set of 9 regressors, and the smallest cholesky pivot element being 6.322e-08. Reduce max_iter or increase eps parameters.\n",
            "  ConvergenceWarning)\n",
            "/Users/thepound/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/least_angle.py:578: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 9 iterations, i.e. alpha=7.535e-01, with an active set of 9 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
            "  ConvergenceWarning)\n",
            "/Users/thepound/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/least_angle.py:578: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 10 iterations, i.e. alpha=6.298e-01, with an active set of 10 regressors, and the smallest cholesky pivot element being 6.322e-08. Reduce max_iter or increase eps parameters.\n",
            "  ConvergenceWarning)\n",
            "/Users/thepound/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/least_angle.py:604: ConvergenceWarning: Early stopping the lars path, as the residues are small and the current value of alpha is no longer well controlled. 11 iterations, alpha=7.383e-01, previous alpha=6.144e-01, with an active set of 10 regressors.\n",
            "  ConvergenceWarning)\n",
            "/Users/thepound/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/least_angle.py:578: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 4 iterations, i.e. alpha=1.147e+00, with an active set of 4 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.\n",
            "  ConvergenceWarning)\n",
            "/Users/thepound/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/least_angle.py:578: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 9 iterations, i.e. alpha=8.014e-01, with an active set of 7 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.\n",
            "  ConvergenceWarning)\n",
            "/Users/thepound/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/least_angle.py:578: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 9 iterations, i.e. alpha=8.010e-01, with an active set of 7 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.\n",
            "  ConvergenceWarning)\n",
            "/Users/thepound/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/least_angle.py:578: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 12 iterations, i.e. alpha=5.693e-01, with an active set of 10 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.\n",
            "  ConvergenceWarning)\n",
            "/Users/thepound/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/least_angle.py:578: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 13 iterations, i.e. alpha=5.099e-01, with an active set of 11 regressors, and the smallest cholesky pivot element being 2.581e-08. Reduce max_iter or increase eps parameters.\n",
            "  ConvergenceWarning)\n",
            "/Users/thepound/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/least_angle.py:578: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 19 iterations, i.e. alpha=3.948e-01, with an active set of 17 regressors, and the smallest cholesky pivot element being 1.054e-08. Reduce max_iter or increase eps parameters.\n",
            "  ConvergenceWarning)\n",
            "/Users/thepound/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/least_angle.py:604: ConvergenceWarning: Early stopping the lars path, as the residues are small and the current value of alpha is no longer well controlled. 32 iterations, alpha=3.137e-01, previous alpha=3.116e-01, with an active set of 27 regressors.\n",
            "  ConvergenceWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "/Users/thepound/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/least_angle.py:578: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 72 iterations, i.e. alpha=9.477e-02, with an active set of 62 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
            "  ConvergenceWarning)\n",
            "/Users/thepound/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/least_angle.py:578: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 78 iterations, i.e. alpha=8.464e-02, with an active set of 68 regressors, and the smallest cholesky pivot element being 2.581e-08. Reduce max_iter or increase eps parameters.\n",
            "  ConvergenceWarning)\n",
            "/Users/thepound/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/least_angle.py:578: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 78 iterations, i.e. alpha=8.464e-02, with an active set of 68 regressors, and the smallest cholesky pivot element being 9.003e-08. Reduce max_iter or increase eps parameters.\n",
            "  ConvergenceWarning)\n",
            "/Users/thepound/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/least_angle.py:604: ConvergenceWarning: Early stopping the lars path, as the residues are small and the current value of alpha is no longer well controlled. 80 iterations, alpha=7.521e-02, previous alpha=7.331e-02, with an active set of 69 regressors.\n",
            "  ConvergenceWarning)\n",
            "/Users/thepound/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/least_angle.py:578: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 4 iterations, i.e. alpha=1.372e+00, with an active set of 4 regressors, and the smallest cholesky pivot element being 7.146e-08. Reduce max_iter or increase eps parameters.\n",
            "  ConvergenceWarning)\n",
            "/Users/thepound/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/least_angle.py:578: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 8 iterations, i.e. alpha=9.825e-01, with an active set of 8 regressors, and the smallest cholesky pivot element being 7.146e-08. Reduce max_iter or increase eps parameters.\n",
            "  ConvergenceWarning)\n",
            "/Users/thepound/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/least_angle.py:578: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 10 iterations, i.e. alpha=6.732e-01, with an active set of 10 regressors, and the smallest cholesky pivot element being 7.146e-08. Reduce max_iter or increase eps parameters.\n",
            "  ConvergenceWarning)\n",
            "/Users/thepound/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/least_angle.py:578: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 14 iterations, i.e. alpha=5.285e-01, with an active set of 12 regressors, and the smallest cholesky pivot element being 7.146e-08. Reduce max_iter or increase eps parameters.\n",
            "  ConvergenceWarning)\n",
            "/Users/thepound/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/least_angle.py:604: ConvergenceWarning: Early stopping the lars path, as the residues are small and the current value of alpha is no longer well controlled. 16 iterations, alpha=5.185e-01, previous alpha=5.185e-01, with an active set of 15 regressors.\n",
            "  ConvergenceWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "LassoLarsCV(copy_X=True, cv=10, eps=2.220446049250313e-16, fit_intercept=True,\n",
              "            max_iter=500, max_n_alphas=1000, n_jobs=None, normalize=True,\n",
              "            positive=False, precompute=False, verbose=False)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IIXrzaeXzbxb",
        "colab_type": "code",
        "colab": {},
        "outputId": "a8ad7298-d823-4e16-c5b2-97201e664569"
      },
      "source": [
        "# create a new table called predictors_model that loading all predictors name from listofallpredictors.\n",
        "predictors_model = pd.DataFrame(listofallpredictors)\n",
        "\n",
        "# rename the column name of predictors_model to 'label'.\n",
        "predictors_model.columns = ['label']\n",
        "\n",
        "# add a new column called 'coeff' and append all coefficents from regression model.\n",
        "predictors_model['coeff'] = model.coef_\n",
        "\n",
        "# for loop that go through predictor_model table and print out the coefficent with name that larger than zero.   \n",
        "for index, row in predictors_model.iterrows():\n",
        "    if row['coeff'] > 0:\n",
        "        print(row.values)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['B01001014' 0.8558381626911589]\n",
            "['B01001036' 2.505359141066419]\n",
            "['B01001037' 0.8893251027424457]\n",
            "['B01001038' 1.5316252934128964]\n",
            "['B02001005' 0.4125308153688556]\n",
            "['B13014026' 0.48003512203884835]\n",
            "['B13014027' 0.6978359257347158]\n",
            "['B13016001' 875052393.5768428]\n",
            "['B19001017' 1.4834386045523393]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tE6j6lfSzbxg",
        "colab_type": "text"
      },
      "source": [
        "# Question 2:\n",
        "['B01001014' 0.8557908775529921] Males aged 40 to 44 Years.\n",
        "If there is one more Males aged 40 to 44 Years, we will sell 0. 8557908775529921 unit more Bobo Bars.\n",
        "\n",
        "['B01001036' 2.505392496591849] Females aged 30 to 34 Years.\n",
        "If there is one more Females aged 30 to 34 Years, we will sell 2.505392496591849 unit more Bobo Bars.\n",
        "        \n",
        "['B01001037' 0.8894214357013622] Females aged 35 to 39 Years.\n",
        "If there is one more Females aged 35 to 39 Years, we will sell 0.8894214357013622 unit more Bobo Bars.\n",
        "\n",
        "['B01001038' 1.5315839680821497] Females aged 40 to 44 Years.\n",
        "If there is one more Females aged 40 to 44 Years, we will sell 1.5315839680821497 unit more Bobo Bars.\n",
        "        \n",
        "['B02001005' 0.4125408937426837] Asian Alone\n",
        "If there is one more Asian Alone, we will sell 0.4125408937426837 unit more Bobo Bars.\n",
        "        \n",
        "['B13014026' 0.4800240326923769] Women 15 to 50 Years Who Had a Birth in the Past 12 Months with Bachelor's Degree\n",
        "If there is one more Women 15 to 50 Years Who Had a Birth in the Past 12 Months with Bachelor's Degree, we will sell 0.4800240326923769 unit more Bobo Bars.\n",
        "\n",
        "['B13014027' 0.6977454940063235] Women 15 to 50 Years Who Had a Birth in the Past 12 Months with Graduate or Professional Degree\n",
        "If there is one more Women 15 to 50 Years Who Had a Birth in the Past 12 Months with Graduate or Professional Degree, we will sell 0.6977454940063235 unit more Bobo Bars.\n",
        "\n",
        "['B13016001' 874922971.7249781] Women 15 to 50 Years Who Had a Birth in the Past 12 Months\n",
        "If there is one more Women 15 to 50 Years Who Had a Birth in the Past 12 Months, we will sell 874922971.7249781 unit more Bobo Bars.\n",
        "\n",
        "['B19001017' 1.4834465563617387] Household with income $200,000 or More.\n",
        "If there is one more Household with income $200,000 or More, we will sell 1.4834465563617387 unit more Bobo Bars.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wo7MOWOTzbxi",
        "colab_type": "text"
      },
      "source": [
        "# Question 3:\n",
        "If I had to report only two census variables to my boss that most steeply predicted sales, the first one would be \n",
        "Women 15 to 50 Years Who Had a Birth in the Past 12 Months and the second one would be Females aged 30 to 34 Years."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g2bY1yXSzbxk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "id": "zCgkEVpfzbxo",
        "colab_type": "code",
        "colab": {},
        "outputId": "b43289bb-8ae9-4397-d431-4054a85bcf00"
      },
      "source": [
        "# mean squared error \n",
        "from sklearn.metrics import mean_squared_error\n",
        "train_error = mean_squared_error(tar_train, model.predict(pred_train))\n",
        "print ('training data MSE')\n",
        "print(train_error)\n",
        "\n",
        "test_error = mean_squared_error(tar_test, model.predict(pred_test))\n",
        "print ('testing data MSE')\n",
        "print(test_error)\n",
        "        \n",
        "# Question 4:    \n",
        "# The mean squared error for training data is 22025.312777378716 and for testing data is 41549.12573000182, \n",
        "# which are not similar. The mean squared error is the measurement of how close a fitted line is to the \n",
        "# data points. The smaller MSE is, the closer the fits is to the data. Since the model is regressed by training\n",
        "# data, the MSE for training data has a less value, which means fitting better, than testing data, make a lot of sense."
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "training data MSE\n",
            "22025.4165060657\n",
            "testing data MSE\n",
            "41549.36952993123\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EzBhC-y7zbxr",
        "colab_type": "text"
      },
      "source": [
        "# Question 4:    \n",
        " The mean squared error for training data is 22025.312777378716 and for testing data is 41549.12573000182, \n",
        " which are not similar. The mean squared error is the measurement of how close a fitted line is to the \n",
        " data points. The smaller MSE is, the closer the fits is to the data. Since the model is regressed by training\n",
        " data, the MSE for training data has a less value, which means fitting better, than testing data, makes a lot of sense."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1Ljxu2tgzbxs",
        "colab_type": "code",
        "colab": {},
        "outputId": "6c027a43-5e97-4bbd-a7f9-7dde3f3c5328"
      },
      "source": [
        "#r squared\n",
        "rsquared_train = model.score(pred_train, tar_train)\n",
        "print ('training data R-square')\n",
        "print(rsquared_train)\n",
        "\n",
        "rsquared_test = model.score(pred_test, tar_test)\n",
        "print ('testing data R-square')\n",
        "print(rsquared_test)\n",
        "\n",
        "# The R-squared for training data is 0.24002827375880997 and the R-squared for testing data is \n",
        "# 0.17587122769388464. Through comparing the R-squared value, we could know that the training \n",
        "# data set has a better regression model as it has a larger R-squared value.\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "training data R-square\n",
            "0.24002469465552534\n",
            "testing data R-square\n",
            "0.17586639191135045\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3oTiiOZVzbxw",
        "colab_type": "text"
      },
      "source": [
        "# Question 5: \n",
        "I would say Census data is not a good fit of predicting sales amount. Even though training data would show\n",
        "a better fit than the actual testing data, the MSE for training data set is still a bit large and \n",
        "the R-squared value of training data set is too small to make a good prediction. In both training date\n",
        "set and the testing data set, the MSE and R-squared value are not sufficient enough to make prediction\n",
        "about the sales. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nsda3agjzbxw",
        "colab_type": "code",
        "colab": {},
        "outputId": "a0e0d36e-b1b2-49b2-eefe-58d847ad7509"
      },
      "source": [
        "print(\"y interecept:\")\n",
        "print(model.intercept_)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "y interecept:\n",
            "22.195868891182577\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gnslWO6vzbxz",
        "colab_type": "text"
      },
      "source": [
        "# Question 6: \n",
        "According to the intercept, the baseline sales number is 22.194697684317433. Practically, it means when value of every\n",
        "variable is 0, no 40 to 44 years old women or anything, there are 22.194697684317433 Bobo bars will be sold."
      ]
    }
  ]
}
